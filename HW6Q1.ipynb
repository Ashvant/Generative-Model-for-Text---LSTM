{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### REG No: 8569202378"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NAME: Ashvant Ram Selvam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fQUJlPdz6Ns8"
   },
   "source": [
    "Concat the text files to one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 86,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10449,
     "status": "ok",
     "timestamp": 1524557225250,
     "user": {
      "displayName": "Ashvant Ram Selvam",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "113072397485214928003"
     },
     "user_tz": 420
    },
    "id": "-T01S7nX6fDu",
    "outputId": "a0f0dae3-c10c-44d7-9ab3-a9b5460d4d8d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-aaaaf3e6-bd37-41a3-a456-443ac27329f7\" name=\"files[]\" multiple disabled />\n",
       "     <output id=\"result-aaaaf3e6-bd37-41a3-a456-443ac27329f7\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving weights.best (1).hdf5 to weights.best (1) (1).hdf5\n",
      "User uploaded file \"weights.best (1).hdf5\" with length 825328 bytes\n"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()\n",
    "for fn in uploaded.keys():\n",
    "  print('User uploaded file \"{name}\" with length {length} bytes'.format(name=fn, length=len(uploaded[fn])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i. Concatenate your text files to create a corpus of Russell’s writings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The books in the data set are read and concatenated into the full data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "xMEK6VOR6Ns9"
   },
   "outputs": [],
   "source": [
    "filenames = ['book1.txt','book2.txt','book3.txt','book4.txt']\n",
    "with open('fullData.txt', 'w') as outfile:\n",
    "    for fname in filenames:\n",
    "        with open(fname) as infile:\n",
    "            for line in infile:\n",
    "                outfile.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "fEzzS8Nv6NtB"
   },
   "outputs": [],
   "source": [
    "inputFile = 'fullData.txt'\n",
    "fread = open(inputFile)\n",
    "dataArray = []\n",
    "for line in fread:\n",
    "    line = line.strip()\n",
    "    for code in line.encode('ascii','ignore'):\n",
    "        dataArray.append(code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ii. Use a character-level representation for this model by using extended ASCII\n",
    "that has N = 256 characters. Each character will be encoded into a an integer\n",
    "using its ASCII code. Rescale the integers to the range [0, 1], because LSTM uses a sigmoid activation function. LSTM will receive the rescaled integers\n",
    "as its input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ASCII encoded values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 17034
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 308,
     "status": "ok",
     "timestamp": 1524557180687,
     "user": {
      "displayName": "Ashvant Ram Selvam",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "113072397485214928003"
     },
     "user_tz": 420
    },
    "id": "hlxuiQlE6NtJ",
    "outputId": "3aa730d7-8aea-4223-f9f4-d44260a40670"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[80,\n",
       " 114,\n",
       " 111,\n",
       " 100,\n",
       " 117,\n",
       " 99,\n",
       " 101,\n",
       " 100,\n",
       " 32,\n",
       " 98,\n",
       " 121,\n",
       " 32,\n",
       " 71,\n",
       " 111,\n",
       " 114,\n",
       " 100,\n",
       " 111,\n",
       " 110,\n",
       " 32,\n",
       " 75,\n",
       " 101,\n",
       " 101,\n",
       " 110,\n",
       " 101,\n",
       " 114,\n",
       " 84,\n",
       " 72,\n",
       " 69,\n",
       " 32,\n",
       " 80,\n",
       " 82,\n",
       " 79,\n",
       " 66,\n",
       " 76,\n",
       " 69,\n",
       " 77,\n",
       " 83,\n",
       " 32,\n",
       " 79,\n",
       " 70,\n",
       " 32,\n",
       " 80,\n",
       " 72,\n",
       " 73,\n",
       " 76,\n",
       " 79,\n",
       " 83,\n",
       " 79,\n",
       " 80,\n",
       " 72,\n",
       " 89,\n",
       " 66,\n",
       " 121,\n",
       " 32,\n",
       " 66,\n",
       " 101,\n",
       " 114,\n",
       " 116,\n",
       " 114,\n",
       " 97,\n",
       " 110,\n",
       " 100,\n",
       " 32,\n",
       " 82,\n",
       " 117,\n",
       " 115,\n",
       " 115,\n",
       " 101,\n",
       " 108,\n",
       " 108,\n",
       " 80,\n",
       " 82,\n",
       " 69,\n",
       " 70,\n",
       " 65,\n",
       " 67,\n",
       " 69,\n",
       " 73,\n",
       " 110,\n",
       " 32,\n",
       " 116,\n",
       " 104,\n",
       " 101,\n",
       " 32,\n",
       " 102,\n",
       " 111,\n",
       " 108,\n",
       " 108,\n",
       " 111,\n",
       " 119,\n",
       " 105,\n",
       " 110,\n",
       " 103,\n",
       " 32,\n",
       " 112,\n",
       " 97,\n",
       " 103,\n",
       " 101,\n",
       " 115,\n",
       " 32,\n",
       " 73,\n",
       " 32,\n",
       " 104,\n",
       " 97,\n",
       " 118,\n",
       " 101,\n",
       " 32,\n",
       " 99,\n",
       " 111,\n",
       " 110,\n",
       " 102,\n",
       " 105,\n",
       " 110,\n",
       " 101,\n",
       " 100,\n",
       " 32,\n",
       " 109,\n",
       " 121,\n",
       " 115,\n",
       " 101,\n",
       " 108,\n",
       " 102,\n",
       " 32,\n",
       " 105,\n",
       " 110,\n",
       " 32,\n",
       " 116,\n",
       " 104,\n",
       " 101,\n",
       " 32,\n",
       " 109,\n",
       " 97,\n",
       " 105,\n",
       " 110,\n",
       " 32,\n",
       " 116,\n",
       " 111,\n",
       " 32,\n",
       " 116,\n",
       " 104,\n",
       " 111,\n",
       " 115,\n",
       " 101,\n",
       " 112,\n",
       " 114,\n",
       " 111,\n",
       " 98,\n",
       " 108,\n",
       " 101,\n",
       " 109,\n",
       " 115,\n",
       " 32,\n",
       " 111,\n",
       " 102,\n",
       " 32,\n",
       " 112,\n",
       " 104,\n",
       " 105,\n",
       " 108,\n",
       " 111,\n",
       " 115,\n",
       " 111,\n",
       " 112,\n",
       " 104,\n",
       " 121,\n",
       " 32,\n",
       " 105,\n",
       " 110,\n",
       " 32,\n",
       " 114,\n",
       " 101,\n",
       " 103,\n",
       " 97,\n",
       " 114,\n",
       " 100,\n",
       " 32,\n",
       " 116,\n",
       " 111,\n",
       " 32,\n",
       " 119,\n",
       " 104,\n",
       " 105,\n",
       " 99,\n",
       " 104,\n",
       " 32,\n",
       " 73,\n",
       " 32,\n",
       " 116,\n",
       " 104,\n",
       " 111,\n",
       " 117,\n",
       " 103,\n",
       " 104,\n",
       " 116,\n",
       " 32,\n",
       " 105,\n",
       " 116,\n",
       " 32,\n",
       " 112,\n",
       " 111,\n",
       " 115,\n",
       " 115,\n",
       " 105,\n",
       " 98,\n",
       " 108,\n",
       " 101,\n",
       " 32,\n",
       " 116,\n",
       " 111,\n",
       " 32,\n",
       " 115,\n",
       " 97,\n",
       " 121,\n",
       " 115,\n",
       " 111,\n",
       " 109,\n",
       " 101,\n",
       " 116,\n",
       " 104,\n",
       " 105,\n",
       " 110,\n",
       " 103,\n",
       " 32,\n",
       " 112,\n",
       " 111,\n",
       " 115,\n",
       " 105,\n",
       " 116,\n",
       " 105,\n",
       " 118,\n",
       " 101,\n",
       " 32,\n",
       " 97,\n",
       " 110,\n",
       " 100,\n",
       " 32,\n",
       " 99,\n",
       " 111,\n",
       " 110,\n",
       " 115,\n",
       " 116,\n",
       " 114,\n",
       " 117,\n",
       " 99,\n",
       " 116,\n",
       " 105,\n",
       " 118,\n",
       " 101,\n",
       " 44,\n",
       " 32,\n",
       " 115,\n",
       " 105,\n",
       " 110,\n",
       " 99,\n",
       " 101,\n",
       " 32,\n",
       " 109,\n",
       " 101,\n",
       " 114,\n",
       " 101,\n",
       " 108,\n",
       " 121,\n",
       " 32,\n",
       " 110,\n",
       " 101,\n",
       " 103,\n",
       " 97,\n",
       " 116,\n",
       " 105,\n",
       " 118,\n",
       " 101,\n",
       " 32,\n",
       " 99,\n",
       " 114,\n",
       " 105,\n",
       " 116,\n",
       " 105,\n",
       " 99,\n",
       " 105,\n",
       " 115,\n",
       " 109,\n",
       " 115,\n",
       " 101,\n",
       " 101,\n",
       " 109,\n",
       " 101,\n",
       " 100,\n",
       " 32,\n",
       " 111,\n",
       " 117,\n",
       " 116,\n",
       " 32,\n",
       " 111,\n",
       " 102,\n",
       " 32,\n",
       " 112,\n",
       " 108,\n",
       " 97,\n",
       " 99,\n",
       " 101,\n",
       " 46,\n",
       " 32,\n",
       " 70,\n",
       " 111,\n",
       " 114,\n",
       " 32,\n",
       " 116,\n",
       " 104,\n",
       " 105,\n",
       " 115,\n",
       " 32,\n",
       " 114,\n",
       " 101,\n",
       " 97,\n",
       " 115,\n",
       " 111,\n",
       " 110,\n",
       " 44,\n",
       " 32,\n",
       " 116,\n",
       " 104,\n",
       " 101,\n",
       " 111,\n",
       " 114,\n",
       " 121,\n",
       " 32,\n",
       " 111,\n",
       " 102,\n",
       " 32,\n",
       " 107,\n",
       " 110,\n",
       " 111,\n",
       " 119,\n",
       " 108,\n",
       " 101,\n",
       " 100,\n",
       " 103,\n",
       " 101,\n",
       " 32,\n",
       " 111,\n",
       " 99,\n",
       " 99,\n",
       " 117,\n",
       " 112,\n",
       " 105,\n",
       " 101,\n",
       " 115,\n",
       " 32,\n",
       " 97,\n",
       " 108,\n",
       " 97,\n",
       " 114,\n",
       " 103,\n",
       " 101,\n",
       " 114,\n",
       " 32,\n",
       " 115,\n",
       " 112,\n",
       " 97,\n",
       " 99,\n",
       " 101,\n",
       " 32,\n",
       " 116,\n",
       " 104,\n",
       " 97,\n",
       " 110,\n",
       " 32,\n",
       " 109,\n",
       " 101,\n",
       " 116,\n",
       " 97,\n",
       " 112,\n",
       " 104,\n",
       " 121,\n",
       " 115,\n",
       " 105,\n",
       " 99,\n",
       " 115,\n",
       " 32,\n",
       " 105,\n",
       " 110,\n",
       " 32,\n",
       " 116,\n",
       " 104,\n",
       " 101,\n",
       " 32,\n",
       " 112,\n",
       " 114,\n",
       " 101,\n",
       " 115,\n",
       " 101,\n",
       " 110,\n",
       " 116,\n",
       " 32,\n",
       " 118,\n",
       " 111,\n",
       " 108,\n",
       " 117,\n",
       " 109,\n",
       " 101,\n",
       " 44,\n",
       " 32,\n",
       " 97,\n",
       " 110,\n",
       " 100,\n",
       " 32,\n",
       " 115,\n",
       " 111,\n",
       " 109,\n",
       " 101,\n",
       " 32,\n",
       " 116,\n",
       " 111,\n",
       " 112,\n",
       " 105,\n",
       " 99,\n",
       " 115,\n",
       " 109,\n",
       " 117,\n",
       " 99,\n",
       " 104,\n",
       " 32,\n",
       " 100,\n",
       " 105,\n",
       " 115,\n",
       " 99,\n",
       " 117,\n",
       " 115,\n",
       " 115,\n",
       " 101,\n",
       " 100,\n",
       " 32,\n",
       " 98,\n",
       " 121,\n",
       " 32,\n",
       " 112,\n",
       " 104,\n",
       " 105,\n",
       " 108,\n",
       " 111,\n",
       " 115,\n",
       " 111,\n",
       " 112,\n",
       " 104,\n",
       " 101,\n",
       " 114,\n",
       " 115,\n",
       " 32,\n",
       " 97,\n",
       " 114,\n",
       " 101,\n",
       " 32,\n",
       " 116,\n",
       " 114,\n",
       " 101,\n",
       " 97,\n",
       " 116,\n",
       " 101,\n",
       " 100,\n",
       " 32,\n",
       " 118,\n",
       " 101,\n",
       " 114,\n",
       " 121,\n",
       " 32,\n",
       " 98,\n",
       " 114,\n",
       " 105,\n",
       " 101,\n",
       " 102,\n",
       " 108,\n",
       " 121,\n",
       " 44,\n",
       " 32,\n",
       " 105,\n",
       " 102,\n",
       " 32,\n",
       " 97,\n",
       " 116,\n",
       " 32,\n",
       " 97,\n",
       " 108,\n",
       " 108,\n",
       " 46,\n",
       " 73,\n",
       " 32,\n",
       " 104,\n",
       " 97,\n",
       " 118,\n",
       " 101,\n",
       " 32,\n",
       " 100,\n",
       " 101,\n",
       " 114,\n",
       " 105,\n",
       " 118,\n",
       " 101,\n",
       " 100,\n",
       " 32,\n",
       " 118,\n",
       " 97,\n",
       " 108,\n",
       " 117,\n",
       " 97,\n",
       " 98,\n",
       " 108,\n",
       " 101,\n",
       " 32,\n",
       " 97,\n",
       " 115,\n",
       " 115,\n",
       " 105,\n",
       " 115,\n",
       " 116,\n",
       " 97,\n",
       " 110,\n",
       " 99,\n",
       " 101,\n",
       " 32,\n",
       " 102,\n",
       " 114,\n",
       " 111,\n",
       " 109,\n",
       " 32,\n",
       " 117,\n",
       " 110,\n",
       " 112,\n",
       " 117,\n",
       " 98,\n",
       " 108,\n",
       " 105,\n",
       " 115,\n",
       " 104,\n",
       " 101,\n",
       " 100,\n",
       " 32,\n",
       " 119,\n",
       " 114,\n",
       " 105,\n",
       " 116,\n",
       " 105,\n",
       " 110,\n",
       " 103,\n",
       " 115,\n",
       " 32,\n",
       " 111,\n",
       " 102,\n",
       " 32,\n",
       " 71,\n",
       " 46,\n",
       " 32,\n",
       " 69,\n",
       " 46,\n",
       " 77,\n",
       " 111,\n",
       " 111,\n",
       " 114,\n",
       " 101,\n",
       " 32,\n",
       " 97,\n",
       " 110,\n",
       " 100,\n",
       " 32,\n",
       " 74,\n",
       " 46,\n",
       " 32,\n",
       " 77,\n",
       " 46,\n",
       " 32,\n",
       " 75,\n",
       " 101,\n",
       " 121,\n",
       " 110,\n",
       " 101,\n",
       " 115,\n",
       " 58,\n",
       " 32,\n",
       " 102,\n",
       " 114,\n",
       " 111,\n",
       " 109,\n",
       " 32,\n",
       " 116,\n",
       " 104,\n",
       " 101,\n",
       " 32,\n",
       " 102,\n",
       " 111,\n",
       " 114,\n",
       " 109,\n",
       " 101,\n",
       " 114,\n",
       " 44,\n",
       " 32,\n",
       " 97,\n",
       " 115,\n",
       " 32,\n",
       " 114,\n",
       " 101,\n",
       " 103,\n",
       " 97,\n",
       " 114,\n",
       " 100,\n",
       " 115,\n",
       " 32,\n",
       " 116,\n",
       " 104,\n",
       " 101,\n",
       " 32,\n",
       " 114,\n",
       " 101,\n",
       " 108,\n",
       " 97,\n",
       " 116,\n",
       " 105,\n",
       " 111,\n",
       " 110,\n",
       " 115,\n",
       " 111,\n",
       " 102,\n",
       " 32,\n",
       " 115,\n",
       " 101,\n",
       " 110,\n",
       " 115,\n",
       " 101,\n",
       " 45,\n",
       " 100,\n",
       " 97,\n",
       " 116,\n",
       " 97,\n",
       " 32,\n",
       " 116,\n",
       " 111,\n",
       " 32,\n",
       " 112,\n",
       " 104,\n",
       " 121,\n",
       " 115,\n",
       " 105,\n",
       " 99,\n",
       " 97,\n",
       " 108,\n",
       " 32,\n",
       " 111,\n",
       " 98,\n",
       " 106,\n",
       " 101,\n",
       " 99,\n",
       " 116,\n",
       " 115,\n",
       " 44,\n",
       " 32,\n",
       " 97,\n",
       " 110,\n",
       " 100,\n",
       " 32,\n",
       " 102,\n",
       " 114,\n",
       " 111,\n",
       " 109,\n",
       " 32,\n",
       " 116,\n",
       " 104,\n",
       " 101,\n",
       " 32,\n",
       " 108,\n",
       " 97,\n",
       " 116,\n",
       " 116,\n",
       " 101,\n",
       " 114,\n",
       " 32,\n",
       " 97,\n",
       " 115,\n",
       " 32,\n",
       " 114,\n",
       " 101,\n",
       " 103,\n",
       " 97,\n",
       " 114,\n",
       " 100,\n",
       " 115,\n",
       " 112,\n",
       " 114,\n",
       " 111,\n",
       " 98,\n",
       " 97,\n",
       " 98,\n",
       " 105,\n",
       " 108,\n",
       " 105,\n",
       " 116,\n",
       " 121,\n",
       " 32,\n",
       " 97,\n",
       " 110,\n",
       " 100,\n",
       " 32,\n",
       " 105,\n",
       " 110,\n",
       " 100,\n",
       " 117,\n",
       " 99,\n",
       " 116,\n",
       " 105,\n",
       " 111,\n",
       " 110,\n",
       " 46,\n",
       " 32,\n",
       " 73,\n",
       " 32,\n",
       " 104,\n",
       " 97,\n",
       " 118,\n",
       " 101,\n",
       " 32,\n",
       " 97,\n",
       " 108,\n",
       " 115,\n",
       " 111,\n",
       " 32,\n",
       " 112,\n",
       " 114,\n",
       " 111,\n",
       " 102,\n",
       " 105,\n",
       " 116,\n",
       " 101,\n",
       " 100,\n",
       " 32,\n",
       " 103,\n",
       " 114,\n",
       " 101,\n",
       " 97,\n",
       " 116,\n",
       " 108,\n",
       " 121,\n",
       " 32,\n",
       " 98,\n",
       " 121,\n",
       " 32,\n",
       " 116,\n",
       " 104,\n",
       " 101,\n",
       " 99,\n",
       " 114,\n",
       " 105,\n",
       " 116,\n",
       " 105,\n",
       " 99,\n",
       " 105,\n",
       " 115,\n",
       " 109,\n",
       " 115,\n",
       " 32,\n",
       " 97,\n",
       " 110,\n",
       " 100,\n",
       " 32,\n",
       " 115,\n",
       " 117,\n",
       " 103,\n",
       " 103,\n",
       " 101,\n",
       " 115,\n",
       " 116,\n",
       " 105,\n",
       " 111,\n",
       " 110,\n",
       " 115,\n",
       " 32,\n",
       " 111,\n",
       " 102,\n",
       " 32,\n",
       " 80,\n",
       " 114,\n",
       " 111,\n",
       " 102,\n",
       " 101,\n",
       " 115,\n",
       " 115,\n",
       " 111,\n",
       " 114,\n",
       " 32,\n",
       " 71,\n",
       " 105,\n",
       " 108,\n",
       " 98,\n",
       " 101,\n",
       " 114,\n",
       " 116,\n",
       " 32,\n",
       " 77,\n",
       " 117,\n",
       " 114,\n",
       " 114,\n",
       " 97,\n",
       " 121,\n",
       " 46,\n",
       " 49,\n",
       " 57,\n",
       " 49,\n",
       " 50,\n",
       " 67,\n",
       " 72,\n",
       " 65,\n",
       " 80,\n",
       " 84,\n",
       " 69,\n",
       " 82,\n",
       " 32,\n",
       " 73,\n",
       " 46,\n",
       " 32,\n",
       " 65,\n",
       " 80,\n",
       " 80,\n",
       " 69,\n",
       " 65,\n",
       " 82,\n",
       " 65,\n",
       " 78,\n",
       " 67,\n",
       " 69,\n",
       " 32,\n",
       " 65,\n",
       " 78,\n",
       " 68,\n",
       " 32,\n",
       " 82,\n",
       " 69,\n",
       " 65,\n",
       " 76,\n",
       " 73,\n",
       " 84,\n",
       " 89,\n",
       " 73,\n",
       " 115,\n",
       " 32,\n",
       " 116,\n",
       " 104,\n",
       " 101,\n",
       " 114,\n",
       " 101,\n",
       " 32,\n",
       " 97,\n",
       " 110,\n",
       " 121,\n",
       " 32,\n",
       " 107,\n",
       " 110,\n",
       " 111,\n",
       " 119,\n",
       " 108,\n",
       " 101,\n",
       " 100,\n",
       " 103,\n",
       " 101,\n",
       " 32,\n",
       " 105,\n",
       " 110,\n",
       " 32,\n",
       " 116,\n",
       " 104,\n",
       " 101,\n",
       " 32,\n",
       " 119,\n",
       " 111,\n",
       " 114,\n",
       " 108,\n",
       " 100,\n",
       " 32,\n",
       " 119,\n",
       " 104,\n",
       " 105,\n",
       " 99,\n",
       " 104,\n",
       " 32,\n",
       " 105,\n",
       " 115,\n",
       " 32,\n",
       " 115,\n",
       " 111,\n",
       " 32,\n",
       " 99,\n",
       " 101,\n",
       " 114,\n",
       " 116,\n",
       " 97,\n",
       " 105,\n",
       " 110,\n",
       " 32,\n",
       " 116,\n",
       " 104,\n",
       " 97,\n",
       " 116,\n",
       " 32,\n",
       " 110,\n",
       " 111,\n",
       " 114,\n",
       " 101,\n",
       " 97,\n",
       " 115,\n",
       " 111,\n",
       " 110,\n",
       " 97,\n",
       " 98,\n",
       " 108,\n",
       " 101,\n",
       " 32,\n",
       " 109,\n",
       " 97,\n",
       " 110,\n",
       " 32,\n",
       " 99,\n",
       " 111,\n",
       " 117,\n",
       " 108,\n",
       " 100,\n",
       " 32,\n",
       " 100,\n",
       " 111,\n",
       " 117,\n",
       " 98,\n",
       " 116,\n",
       " 32,\n",
       " 105,\n",
       " 116,\n",
       " 63,\n",
       " 32,\n",
       " 84,\n",
       " 104,\n",
       " 105,\n",
       " 115,\n",
       " 32,\n",
       " 113,\n",
       " 117,\n",
       " 101,\n",
       " 115,\n",
       " 116,\n",
       " 105,\n",
       " 111,\n",
       " 110,\n",
       " 44,\n",
       " 32,\n",
       " 119,\n",
       " 104,\n",
       " 105,\n",
       " 99,\n",
       " 104,\n",
       " 32,\n",
       " 97,\n",
       " 116,\n",
       " 32,\n",
       " 102,\n",
       " 105,\n",
       " 114,\n",
       " 115,\n",
       " 116,\n",
       " 32,\n",
       " 115,\n",
       " 105,\n",
       " 103,\n",
       " 104,\n",
       " 116,\n",
       " 32,\n",
       " 109,\n",
       " 105,\n",
       " 103,\n",
       " 104,\n",
       " 116,\n",
       " 110,\n",
       " 111,\n",
       " 116,\n",
       " 32,\n",
       " 115,\n",
       " 101,\n",
       " 101,\n",
       " 109,\n",
       " 32,\n",
       " 100,\n",
       " 105,\n",
       " 102,\n",
       " 102,\n",
       " 105,\n",
       " 99,\n",
       " 117,\n",
       " 108,\n",
       " 116,\n",
       " 44,\n",
       " 32,\n",
       " 105,\n",
       " 115,\n",
       " 32,\n",
       " 114,\n",
       " 101,\n",
       " 97,\n",
       " 108,\n",
       " 108,\n",
       " ...]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataArray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features Scaled to [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "UT9dgQFZ6NtP"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 311,
     "status": "ok",
     "timestamp": 1524557184764,
     "user": {
      "displayName": "Ashvant Ram Selvam",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "113072397485214928003"
     },
     "user_tz": 420
    },
    "id": "BfmfdtRY6NtS",
    "outputId": "1de85e4c-3caa-4eb7-8ffd-2bdb6d665aa2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ashvant/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "norm = MinMaxScaler(feature_range = (0, 1))\n",
    "dataArrayNormalized = norm.fit_transform(np.array(dataArray).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 280,
     "status": "ok",
     "timestamp": 1524557186017,
     "user": {
      "displayName": "Ashvant Ram Selvam",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "113072397485214928003"
     },
     "user_tz": 420
    },
    "id": "sSGIo1846NtV",
    "outputId": "4a106aa9-3045-4f40-d71f-1a8f3459e0fd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "241183"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataArrayNormalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iii. Choose a window size, e.g., W = 100."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iv. Inputs to the network will be the first W −1 = 99 characters of each sequence,\n",
    "and the output of the network will be the L\n",
    "th character of the sequence.\n",
    "Basically, we are training the network to predict the each character using the\n",
    "99 characters that precede it. Slide the window in strides of S = 1 on the\n",
    "text. For example, if W = 5 and S = 1 and we want to train the network\n",
    "with the sequence ABRACADABRA, The first input to the network will be\n",
    "ABRA and the corresponding output will be C. The second input will be\n",
    "BRAC and the second output will be A, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "trainData has the 99 character sequence and trainLabels has the 100th character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "JSOrQhVI6NtY"
   },
   "outputs": [],
   "source": [
    "trainData = []\n",
    "trainLabels = []\n",
    "for i in range(99, len(dataArrayNormalized)):\n",
    "    trainData.append(dataArrayNormalized[i-99:i])\n",
    "    trainLabels.append(dataArray[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 17034
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 303,
     "status": "ok",
     "timestamp": 1524557188322,
     "user": {
      "displayName": "Ashvant Ram Selvam",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "113072397485214928003"
     },
     "user_tz": 420
    },
    "id": "PH79Y4ya6Nta",
    "outputId": "423ddc3f-511a-472d-fb8f-840998a1ebc0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[32,\n",
       " 73,\n",
       " 32,\n",
       " 104,\n",
       " 97,\n",
       " 118,\n",
       " 101,\n",
       " 32,\n",
       " 99,\n",
       " 111,\n",
       " 110,\n",
       " 102,\n",
       " 105,\n",
       " 110,\n",
       " 101,\n",
       " 100,\n",
       " 32,\n",
       " 109,\n",
       " 121,\n",
       " 115,\n",
       " 101,\n",
       " 108,\n",
       " 102,\n",
       " 32,\n",
       " 105,\n",
       " 110,\n",
       " 32,\n",
       " 116,\n",
       " 104,\n",
       " 101,\n",
       " 32,\n",
       " 109,\n",
       " 97,\n",
       " 105,\n",
       " 110,\n",
       " 32,\n",
       " 116,\n",
       " 111,\n",
       " 32,\n",
       " 116,\n",
       " 104,\n",
       " 111,\n",
       " 115,\n",
       " 101,\n",
       " 112,\n",
       " 114,\n",
       " 111,\n",
       " 98,\n",
       " 108,\n",
       " 101,\n",
       " 109,\n",
       " 115,\n",
       " 32,\n",
       " 111,\n",
       " 102,\n",
       " 32,\n",
       " 112,\n",
       " 104,\n",
       " 105,\n",
       " 108,\n",
       " 111,\n",
       " 115,\n",
       " 111,\n",
       " 112,\n",
       " 104,\n",
       " 121,\n",
       " 32,\n",
       " 105,\n",
       " 110,\n",
       " 32,\n",
       " 114,\n",
       " 101,\n",
       " 103,\n",
       " 97,\n",
       " 114,\n",
       " 100,\n",
       " 32,\n",
       " 116,\n",
       " 111,\n",
       " 32,\n",
       " 119,\n",
       " 104,\n",
       " 105,\n",
       " 99,\n",
       " 104,\n",
       " 32,\n",
       " 73,\n",
       " 32,\n",
       " 116,\n",
       " 104,\n",
       " 111,\n",
       " 117,\n",
       " 103,\n",
       " 104,\n",
       " 116,\n",
       " 32,\n",
       " 105,\n",
       " 116,\n",
       " 32,\n",
       " 112,\n",
       " 111,\n",
       " 115,\n",
       " 115,\n",
       " 105,\n",
       " 98,\n",
       " 108,\n",
       " 101,\n",
       " 32,\n",
       " 116,\n",
       " 111,\n",
       " 32,\n",
       " 115,\n",
       " 97,\n",
       " 121,\n",
       " 115,\n",
       " 111,\n",
       " 109,\n",
       " 101,\n",
       " 116,\n",
       " 104,\n",
       " 105,\n",
       " 110,\n",
       " 103,\n",
       " 32,\n",
       " 112,\n",
       " 111,\n",
       " 115,\n",
       " 105,\n",
       " 116,\n",
       " 105,\n",
       " 118,\n",
       " 101,\n",
       " 32,\n",
       " 97,\n",
       " 110,\n",
       " 100,\n",
       " 32,\n",
       " 99,\n",
       " 111,\n",
       " 110,\n",
       " 115,\n",
       " 116,\n",
       " 114,\n",
       " 117,\n",
       " 99,\n",
       " 116,\n",
       " 105,\n",
       " 118,\n",
       " 101,\n",
       " 44,\n",
       " 32,\n",
       " 115,\n",
       " 105,\n",
       " 110,\n",
       " 99,\n",
       " 101,\n",
       " 32,\n",
       " 109,\n",
       " 101,\n",
       " 114,\n",
       " 101,\n",
       " 108,\n",
       " 121,\n",
       " 32,\n",
       " 110,\n",
       " 101,\n",
       " 103,\n",
       " 97,\n",
       " 116,\n",
       " 105,\n",
       " 118,\n",
       " 101,\n",
       " 32,\n",
       " 99,\n",
       " 114,\n",
       " 105,\n",
       " 116,\n",
       " 105,\n",
       " 99,\n",
       " 105,\n",
       " 115,\n",
       " 109,\n",
       " 115,\n",
       " 101,\n",
       " 101,\n",
       " 109,\n",
       " 101,\n",
       " 100,\n",
       " 32,\n",
       " 111,\n",
       " 117,\n",
       " 116,\n",
       " 32,\n",
       " 111,\n",
       " 102,\n",
       " 32,\n",
       " 112,\n",
       " 108,\n",
       " 97,\n",
       " 99,\n",
       " 101,\n",
       " 46,\n",
       " 32,\n",
       " 70,\n",
       " 111,\n",
       " 114,\n",
       " 32,\n",
       " 116,\n",
       " 104,\n",
       " 105,\n",
       " 115,\n",
       " 32,\n",
       " 114,\n",
       " 101,\n",
       " 97,\n",
       " 115,\n",
       " 111,\n",
       " 110,\n",
       " 44,\n",
       " 32,\n",
       " 116,\n",
       " 104,\n",
       " 101,\n",
       " 111,\n",
       " 114,\n",
       " 121,\n",
       " 32,\n",
       " 111,\n",
       " 102,\n",
       " 32,\n",
       " 107,\n",
       " 110,\n",
       " 111,\n",
       " 119,\n",
       " 108,\n",
       " 101,\n",
       " 100,\n",
       " 103,\n",
       " 101,\n",
       " 32,\n",
       " 111,\n",
       " 99,\n",
       " 99,\n",
       " 117,\n",
       " 112,\n",
       " 105,\n",
       " 101,\n",
       " 115,\n",
       " 32,\n",
       " 97,\n",
       " 108,\n",
       " 97,\n",
       " 114,\n",
       " 103,\n",
       " 101,\n",
       " 114,\n",
       " 32,\n",
       " 115,\n",
       " 112,\n",
       " 97,\n",
       " 99,\n",
       " 101,\n",
       " 32,\n",
       " 116,\n",
       " 104,\n",
       " 97,\n",
       " 110,\n",
       " 32,\n",
       " 109,\n",
       " 101,\n",
       " 116,\n",
       " 97,\n",
       " 112,\n",
       " 104,\n",
       " 121,\n",
       " 115,\n",
       " 105,\n",
       " 99,\n",
       " 115,\n",
       " 32,\n",
       " 105,\n",
       " 110,\n",
       " 32,\n",
       " 116,\n",
       " 104,\n",
       " 101,\n",
       " 32,\n",
       " 112,\n",
       " 114,\n",
       " 101,\n",
       " 115,\n",
       " 101,\n",
       " 110,\n",
       " 116,\n",
       " 32,\n",
       " 118,\n",
       " 111,\n",
       " 108,\n",
       " 117,\n",
       " 109,\n",
       " 101,\n",
       " 44,\n",
       " 32,\n",
       " 97,\n",
       " 110,\n",
       " 100,\n",
       " 32,\n",
       " 115,\n",
       " 111,\n",
       " 109,\n",
       " 101,\n",
       " 32,\n",
       " 116,\n",
       " 111,\n",
       " 112,\n",
       " 105,\n",
       " 99,\n",
       " 115,\n",
       " 109,\n",
       " 117,\n",
       " 99,\n",
       " 104,\n",
       " 32,\n",
       " 100,\n",
       " 105,\n",
       " 115,\n",
       " 99,\n",
       " 117,\n",
       " 115,\n",
       " 115,\n",
       " 101,\n",
       " 100,\n",
       " 32,\n",
       " 98,\n",
       " 121,\n",
       " 32,\n",
       " 112,\n",
       " 104,\n",
       " 105,\n",
       " 108,\n",
       " 111,\n",
       " 115,\n",
       " 111,\n",
       " 112,\n",
       " 104,\n",
       " 101,\n",
       " 114,\n",
       " 115,\n",
       " 32,\n",
       " 97,\n",
       " 114,\n",
       " 101,\n",
       " 32,\n",
       " 116,\n",
       " 114,\n",
       " 101,\n",
       " 97,\n",
       " 116,\n",
       " 101,\n",
       " 100,\n",
       " 32,\n",
       " 118,\n",
       " 101,\n",
       " 114,\n",
       " 121,\n",
       " 32,\n",
       " 98,\n",
       " 114,\n",
       " 105,\n",
       " 101,\n",
       " 102,\n",
       " 108,\n",
       " 121,\n",
       " 44,\n",
       " 32,\n",
       " 105,\n",
       " 102,\n",
       " 32,\n",
       " 97,\n",
       " 116,\n",
       " 32,\n",
       " 97,\n",
       " 108,\n",
       " 108,\n",
       " 46,\n",
       " 73,\n",
       " 32,\n",
       " 104,\n",
       " 97,\n",
       " 118,\n",
       " 101,\n",
       " 32,\n",
       " 100,\n",
       " 101,\n",
       " 114,\n",
       " 105,\n",
       " 118,\n",
       " 101,\n",
       " 100,\n",
       " 32,\n",
       " 118,\n",
       " 97,\n",
       " 108,\n",
       " 117,\n",
       " 97,\n",
       " 98,\n",
       " 108,\n",
       " 101,\n",
       " 32,\n",
       " 97,\n",
       " 115,\n",
       " 115,\n",
       " 105,\n",
       " 115,\n",
       " 116,\n",
       " 97,\n",
       " 110,\n",
       " 99,\n",
       " 101,\n",
       " 32,\n",
       " 102,\n",
       " 114,\n",
       " 111,\n",
       " 109,\n",
       " 32,\n",
       " 117,\n",
       " 110,\n",
       " 112,\n",
       " 117,\n",
       " 98,\n",
       " 108,\n",
       " 105,\n",
       " 115,\n",
       " 104,\n",
       " 101,\n",
       " 100,\n",
       " 32,\n",
       " 119,\n",
       " 114,\n",
       " 105,\n",
       " 116,\n",
       " 105,\n",
       " 110,\n",
       " 103,\n",
       " 115,\n",
       " 32,\n",
       " 111,\n",
       " 102,\n",
       " 32,\n",
       " 71,\n",
       " 46,\n",
       " 32,\n",
       " 69,\n",
       " 46,\n",
       " 77,\n",
       " 111,\n",
       " 111,\n",
       " 114,\n",
       " 101,\n",
       " 32,\n",
       " 97,\n",
       " 110,\n",
       " 100,\n",
       " 32,\n",
       " 74,\n",
       " 46,\n",
       " 32,\n",
       " 77,\n",
       " 46,\n",
       " 32,\n",
       " 75,\n",
       " 101,\n",
       " 121,\n",
       " 110,\n",
       " 101,\n",
       " 115,\n",
       " 58,\n",
       " 32,\n",
       " 102,\n",
       " 114,\n",
       " 111,\n",
       " 109,\n",
       " 32,\n",
       " 116,\n",
       " 104,\n",
       " 101,\n",
       " 32,\n",
       " 102,\n",
       " 111,\n",
       " 114,\n",
       " 109,\n",
       " 101,\n",
       " 114,\n",
       " 44,\n",
       " 32,\n",
       " 97,\n",
       " 115,\n",
       " 32,\n",
       " 114,\n",
       " 101,\n",
       " 103,\n",
       " 97,\n",
       " 114,\n",
       " 100,\n",
       " 115,\n",
       " 32,\n",
       " 116,\n",
       " 104,\n",
       " 101,\n",
       " 32,\n",
       " 114,\n",
       " 101,\n",
       " 108,\n",
       " 97,\n",
       " 116,\n",
       " 105,\n",
       " 111,\n",
       " 110,\n",
       " 115,\n",
       " 111,\n",
       " 102,\n",
       " 32,\n",
       " 115,\n",
       " 101,\n",
       " 110,\n",
       " 115,\n",
       " 101,\n",
       " 45,\n",
       " 100,\n",
       " 97,\n",
       " 116,\n",
       " 97,\n",
       " 32,\n",
       " 116,\n",
       " 111,\n",
       " 32,\n",
       " 112,\n",
       " 104,\n",
       " 121,\n",
       " 115,\n",
       " 105,\n",
       " 99,\n",
       " 97,\n",
       " 108,\n",
       " 32,\n",
       " 111,\n",
       " 98,\n",
       " 106,\n",
       " 101,\n",
       " 99,\n",
       " 116,\n",
       " 115,\n",
       " 44,\n",
       " 32,\n",
       " 97,\n",
       " 110,\n",
       " 100,\n",
       " 32,\n",
       " 102,\n",
       " 114,\n",
       " 111,\n",
       " 109,\n",
       " 32,\n",
       " 116,\n",
       " 104,\n",
       " 101,\n",
       " 32,\n",
       " 108,\n",
       " 97,\n",
       " 116,\n",
       " 116,\n",
       " 101,\n",
       " 114,\n",
       " 32,\n",
       " 97,\n",
       " 115,\n",
       " 32,\n",
       " 114,\n",
       " 101,\n",
       " 103,\n",
       " 97,\n",
       " 114,\n",
       " 100,\n",
       " 115,\n",
       " 112,\n",
       " 114,\n",
       " 111,\n",
       " 98,\n",
       " 97,\n",
       " 98,\n",
       " 105,\n",
       " 108,\n",
       " 105,\n",
       " 116,\n",
       " 121,\n",
       " 32,\n",
       " 97,\n",
       " 110,\n",
       " 100,\n",
       " 32,\n",
       " 105,\n",
       " 110,\n",
       " 100,\n",
       " 117,\n",
       " 99,\n",
       " 116,\n",
       " 105,\n",
       " 111,\n",
       " 110,\n",
       " 46,\n",
       " 32,\n",
       " 73,\n",
       " 32,\n",
       " 104,\n",
       " 97,\n",
       " 118,\n",
       " 101,\n",
       " 32,\n",
       " 97,\n",
       " 108,\n",
       " 115,\n",
       " 111,\n",
       " 32,\n",
       " 112,\n",
       " 114,\n",
       " 111,\n",
       " 102,\n",
       " 105,\n",
       " 116,\n",
       " 101,\n",
       " 100,\n",
       " 32,\n",
       " 103,\n",
       " 114,\n",
       " 101,\n",
       " 97,\n",
       " 116,\n",
       " 108,\n",
       " 121,\n",
       " 32,\n",
       " 98,\n",
       " 121,\n",
       " 32,\n",
       " 116,\n",
       " 104,\n",
       " 101,\n",
       " 99,\n",
       " 114,\n",
       " 105,\n",
       " 116,\n",
       " 105,\n",
       " 99,\n",
       " 105,\n",
       " 115,\n",
       " 109,\n",
       " 115,\n",
       " 32,\n",
       " 97,\n",
       " 110,\n",
       " 100,\n",
       " 32,\n",
       " 115,\n",
       " 117,\n",
       " 103,\n",
       " 103,\n",
       " 101,\n",
       " 115,\n",
       " 116,\n",
       " 105,\n",
       " 111,\n",
       " 110,\n",
       " 115,\n",
       " 32,\n",
       " 111,\n",
       " 102,\n",
       " 32,\n",
       " 80,\n",
       " 114,\n",
       " 111,\n",
       " 102,\n",
       " 101,\n",
       " 115,\n",
       " 115,\n",
       " 111,\n",
       " 114,\n",
       " 32,\n",
       " 71,\n",
       " 105,\n",
       " 108,\n",
       " 98,\n",
       " 101,\n",
       " 114,\n",
       " 116,\n",
       " 32,\n",
       " 77,\n",
       " 117,\n",
       " 114,\n",
       " 114,\n",
       " 97,\n",
       " 121,\n",
       " 46,\n",
       " 49,\n",
       " 57,\n",
       " 49,\n",
       " 50,\n",
       " 67,\n",
       " 72,\n",
       " 65,\n",
       " 80,\n",
       " 84,\n",
       " 69,\n",
       " 82,\n",
       " 32,\n",
       " 73,\n",
       " 46,\n",
       " 32,\n",
       " 65,\n",
       " 80,\n",
       " 80,\n",
       " 69,\n",
       " 65,\n",
       " 82,\n",
       " 65,\n",
       " 78,\n",
       " 67,\n",
       " 69,\n",
       " 32,\n",
       " 65,\n",
       " 78,\n",
       " 68,\n",
       " 32,\n",
       " 82,\n",
       " 69,\n",
       " 65,\n",
       " 76,\n",
       " 73,\n",
       " 84,\n",
       " 89,\n",
       " 73,\n",
       " 115,\n",
       " 32,\n",
       " 116,\n",
       " 104,\n",
       " 101,\n",
       " 114,\n",
       " 101,\n",
       " 32,\n",
       " 97,\n",
       " 110,\n",
       " 121,\n",
       " 32,\n",
       " 107,\n",
       " 110,\n",
       " 111,\n",
       " 119,\n",
       " 108,\n",
       " 101,\n",
       " 100,\n",
       " 103,\n",
       " 101,\n",
       " 32,\n",
       " 105,\n",
       " 110,\n",
       " 32,\n",
       " 116,\n",
       " 104,\n",
       " 101,\n",
       " 32,\n",
       " 119,\n",
       " 111,\n",
       " 114,\n",
       " 108,\n",
       " 100,\n",
       " 32,\n",
       " 119,\n",
       " 104,\n",
       " 105,\n",
       " 99,\n",
       " 104,\n",
       " 32,\n",
       " 105,\n",
       " 115,\n",
       " 32,\n",
       " 115,\n",
       " 111,\n",
       " 32,\n",
       " 99,\n",
       " 101,\n",
       " 114,\n",
       " 116,\n",
       " 97,\n",
       " 105,\n",
       " 110,\n",
       " 32,\n",
       " 116,\n",
       " 104,\n",
       " 97,\n",
       " 116,\n",
       " 32,\n",
       " 110,\n",
       " 111,\n",
       " 114,\n",
       " 101,\n",
       " 97,\n",
       " 115,\n",
       " 111,\n",
       " 110,\n",
       " 97,\n",
       " 98,\n",
       " 108,\n",
       " 101,\n",
       " 32,\n",
       " 109,\n",
       " 97,\n",
       " 110,\n",
       " 32,\n",
       " 99,\n",
       " 111,\n",
       " 117,\n",
       " 108,\n",
       " 100,\n",
       " 32,\n",
       " 100,\n",
       " 111,\n",
       " 117,\n",
       " 98,\n",
       " 116,\n",
       " 32,\n",
       " 105,\n",
       " 116,\n",
       " 63,\n",
       " 32,\n",
       " 84,\n",
       " 104,\n",
       " 105,\n",
       " 115,\n",
       " 32,\n",
       " 113,\n",
       " 117,\n",
       " 101,\n",
       " 115,\n",
       " 116,\n",
       " 105,\n",
       " 111,\n",
       " 110,\n",
       " 44,\n",
       " 32,\n",
       " 119,\n",
       " 104,\n",
       " 105,\n",
       " 99,\n",
       " 104,\n",
       " 32,\n",
       " 97,\n",
       " 116,\n",
       " 32,\n",
       " 102,\n",
       " 105,\n",
       " 114,\n",
       " 115,\n",
       " 116,\n",
       " 32,\n",
       " 115,\n",
       " 105,\n",
       " 103,\n",
       " 104,\n",
       " 116,\n",
       " 32,\n",
       " 109,\n",
       " 105,\n",
       " 103,\n",
       " 104,\n",
       " 116,\n",
       " 110,\n",
       " 111,\n",
       " 116,\n",
       " 32,\n",
       " 115,\n",
       " 101,\n",
       " 101,\n",
       " 109,\n",
       " 32,\n",
       " 100,\n",
       " 105,\n",
       " 102,\n",
       " 102,\n",
       " 105,\n",
       " 99,\n",
       " 117,\n",
       " 108,\n",
       " 116,\n",
       " 44,\n",
       " 32,\n",
       " 105,\n",
       " 115,\n",
       " 32,\n",
       " 114,\n",
       " 101,\n",
       " 97,\n",
       " 108,\n",
       " 108,\n",
       " 121,\n",
       " 32,\n",
       " 111,\n",
       " 110,\n",
       " 101,\n",
       " 32,\n",
       " 111,\n",
       " 102,\n",
       " 32,\n",
       " 116,\n",
       " 104,\n",
       " 101,\n",
       " 32,\n",
       " 109,\n",
       " 111,\n",
       " 115,\n",
       " 116,\n",
       " 32,\n",
       " 100,\n",
       " 105,\n",
       " 102,\n",
       " 102,\n",
       " 105,\n",
       " 99,\n",
       " 117,\n",
       " 108,\n",
       " 116,\n",
       " 32,\n",
       " 116,\n",
       " 104,\n",
       " 97,\n",
       " 116,\n",
       " 32,\n",
       " 99,\n",
       " 97,\n",
       " 110,\n",
       " 98,\n",
       " 101,\n",
       " 32,\n",
       " 97,\n",
       " 115,\n",
       " 107,\n",
       " 101,\n",
       " 100,\n",
       " 46,\n",
       " 32,\n",
       " 87,\n",
       " 104,\n",
       " 101,\n",
       " 110,\n",
       " 32,\n",
       " 119,\n",
       " 101,\n",
       " 32,\n",
       " 104,\n",
       " 97,\n",
       " 118,\n",
       " 101,\n",
       " 32,\n",
       " 114,\n",
       " 101,\n",
       " 97,\n",
       " 108,\n",
       " 105,\n",
       " 122,\n",
       " 101,\n",
       " 100,\n",
       " 32,\n",
       " 116,\n",
       " 104,\n",
       " 101,\n",
       " 32,\n",
       " 111,\n",
       " 98,\n",
       " 115,\n",
       " 116,\n",
       " 97,\n",
       " 99,\n",
       " 108,\n",
       " 101,\n",
       " 115,\n",
       " 32,\n",
       " 105,\n",
       " 110,\n",
       " 32,\n",
       " 116,\n",
       " 104,\n",
       " 101,\n",
       " 32,\n",
       " 119,\n",
       " 97,\n",
       " 121,\n",
       " 32,\n",
       " 111,\n",
       " 102,\n",
       " 32,\n",
       " 97,\n",
       " 115,\n",
       " 116,\n",
       " ...]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 315,
     "status": "ok",
     "timestamp": 1524557191024,
     "user": {
      "displayName": "Ashvant Ram Selvam",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "113072397485214928003"
     },
     "user_tz": 420
    },
    "id": "HqtwYvpe6Ntf",
    "outputId": "c6583a7b-ca87-458c-86f3-0c5990e57de7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "241084"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainLabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "v. Note that the output has to be encoded using a one-hot encoding scheme with\n",
    "N = 256 (or less) elements. This means that the network reads integers, but\n",
    "outputs a vector of N = 256 (or less) elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "7ntyjwGF6Ntj"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder(n_values = 256)\n",
    "trainLabelEncoded = ohe.fit_transform(np.array(trainLabels).reshape(-1, 1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One hot encoding of Labels in trainLabelEncoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 267,
     "status": "ok",
     "timestamp": 1524557193145,
     "user": {
      "displayName": "Ashvant Ram Selvam",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "113072397485214928003"
     },
     "user_tz": 420
    },
    "id": "Gt8LtcQH6Ntl",
    "outputId": "395c8a8e-3615-4547-aa33-1c3389ac1ffc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(241084, 256)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainLabelEncoded.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vi. Use a single hidden layer for the LSTM with N = 256 (or less) memory units.\n",
    "vii. Use a Softmax output layer to yield a probability prediction for each of the\n",
    "characters between 0 and 1. This is actually a character classification problem\n",
    "with N classes. Choose log loss (cross entropy) as the objective function for\n",
    "the network (research what it menas).\n",
    "viii. We do not use a test dataset. We are using the whole training dataset to\n",
    "learn the probability of each character in a sequence. We are not seeking for\n",
    "a very accurate model of. Instead we are interested in a generalization of the\n",
    "dataset that can mimic the gist of the text.\n",
    "\n",
    "x. Use model checkpointing to keep the network weights to determine each time\n",
    "an improvement in loss is observed at the end of the epoch. Find the best set\n",
    "of weights in terms of loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "lQX0cKlD6Ntt"
   },
   "outputs": [],
   "source": [
    "trainData = np.array(trainData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "N_C-SuNz6Ntw"
   },
   "outputs": [],
   "source": [
    "trainData = np.reshape(trainData, (trainData.shape[0], trainData.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "cC-013RK6Ntz"
   },
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "newLabels = np_utils.to_categorical(trainLabels,num_classes=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "EcAa-XcD6Nt1"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "FBWg0A9e6Nt5"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM Construction with 256 hidden units and softmax activation and categorical_crossentropy as the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "FmDiNGvP6Nt7"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(units = 100, return_sequences = False, input_shape = (trainData.shape[1], 1)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(units = 256))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units = 256, activation='softmax'))\n",
    "model.compile(optimizer = 'Adam', loss = 'categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "Dvp8OyVloFuk"
   },
   "outputs": [],
   "source": [
    "model.load_weights(\"weights.bestlstm.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ix. Choose a reasonable number of epochs for training (e.g., 30, although the\n",
    "network will need more epochs to yield a better model)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model was repeatedly trained for 200 epochs and the weights were stored and loaded for subsequent evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "id": "fiWZOpYJ6Nt-",
    "outputId": "fcb0b53b-544f-49cc-ae4b-424c72cf3fe9"
   },
   "source": [
    "model.fit(trainData,newLabels, validation_split=0.33, epochs=40, batch_size=4000, callbacks=callbacks_list, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x. Use model checkpointing to keep the network weights to determine each time\n",
    "an improvement in loss is observed at the end of the epoch. Find the best set\n",
    "of weights in terms of loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7444,
     "status": "ok",
     "timestamp": 1524557201126,
     "user": {
      "displayName": "Ashvant Ram Selvam",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "113072397485214928003"
     },
     "user_tz": 420
    },
    "id": "VfmkNMmI6Nto",
    "outputId": "055bb416-98ac-4f37-b44f-92568e8ed91c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "ZLfqRak46Ntr"
   },
   "outputs": [],
   "source": [
    "filepath=\"weights.bestnew.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weights stored through model checkpointing are loaded for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "X9IT4SgDI3SK"
   },
   "outputs": [],
   "source": [
    "model.load_weights(\"weights.best.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "peKRrQzcGtrL"
   },
   "outputs": [],
   "source": [
    "files.download(\"weights.best.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xi. Use the network with the best weights to generate 1000 characters, using the\n",
    "following text as initialization of the network:\n",
    "There are those who take mental phenomena naively, just as they\n",
    "would physical phenomena. This school of psychologists tends not to\n",
    "emphasize the object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "tVkOT4eD6NuC"
   },
   "outputs": [],
   "source": [
    "outputString = \"There are those who take mental phenomena naively, just as they would physical phenomena. This school of psychologists tends not to emphasize the object\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "_cLNQs8P6NuF"
   },
   "outputs": [],
   "source": [
    "testData = []\n",
    "outputString = outputString.strip()\n",
    "i = 0\n",
    "for code in outputString.encode('ascii','ignore'):\n",
    "        if(i<99):\n",
    "          testData.append(code)\n",
    "          i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "uyRhkudh6NuK"
   },
   "outputs": [],
   "source": [
    "testSample = []\n",
    "testSample.append(testData[:99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "V0qFI_Ov6NuM"
   },
   "outputs": [],
   "source": [
    "testDataTransform = norm.transform(testSample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "tzcx3Crb6NuV"
   },
   "outputs": [],
   "source": [
    "testSampleShape = np.reshape(testDataTransform, (testDataTransform.shape[0], testDataTransform.shape[1], 1))\n",
    "output = model.predict(testSampleShape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "oxKbMUYfYYDE"
   },
   "outputs": [],
   "source": [
    "testData.append(np.where(output[0]==max(output[0]))[0][0])\n",
    "for i in range(1000):\n",
    "  testSample = []\n",
    "  testSample.append(testData[1+i:100+i])\n",
    "  testDataTransform = norm.transform(testSample)\n",
    "  testSampleShape = np.reshape(testDataTransform, (testDataTransform.shape[0], testDataTransform.shape[1], 1))\n",
    "  output = model.predict(testSampleShape)\n",
    "  testData.append(np.where(output[0]==max(output[0]))[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 292,
     "status": "ok",
     "timestamp": 1524550626442,
     "user": {
      "displayName": "Ashvant Ram Selvam",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "113072397485214928003"
     },
     "user_tz": 420
    },
    "id": "l1ZLHge2goXP",
    "outputId": "631d51d7-778b-45e7-e01f-4063f4a99224"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are those who take mental phenomena naively, just as they would physical phenomena. This scho th the tael th the tael th the tael th the tael th the tael th the tael that th the taelg of the tannth the tael th the tael th the tael th the tael th the tael th the tael that th the taelg of the tanee  oh ttael th the tael th the tael th the taelgthathe taelgthathe taelgthat thethe taelg of the tane  oah thi e thethe thel th the tael th the tael        th      n   th      n th t   ah t  te the sant tah  the taseat   th t thethe tael th the tael taataI11hewaaI11heaahicaaTTPhehechetteutheihete  toenethentthinghe en taahethaert   that thethe tael that     e       e                e iinience    tahi     n    n    tn the     n   oaahec ie     the  the  taaaaasaa1111eee17111111111111heee eed  iaTthec taaaihaaaaheaaihichidatTTPheaahic   to taTTThe sahictahang         e    II IIRR)ITTRE  rthittin      the                         tr  tstaaheche     the         taaaiI111ees17e do edddheteeihiheiie. aatTThecstTTPTTTTTTTTNNNNNNNNNNTTCERRF  eaeen  taatIh  saaaiT111her e    e e   ta tene               Tn               teei     trittt       tWh h  tahi    tahel      e  ansaaantesaah the  taaaiI11\n"
     ]
    }
   ],
   "source": [
    "predicted = \"\"\n",
    "for i in range(len(testData)):\n",
    "  predicted = predicted + chr(testData[i])\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "64EVcbJ56Nun"
   },
   "source": [
    "The obove are the 1000 subsequent characters printed through LSTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "default_view": {},
   "name": "HW6.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
